{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b20d99ad-aeae-4f3a-aa42-4f08f5cdd54f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract\n",
    "import os\n",
    "import json\n",
    "from pytz import timezone\n",
    "# from pyspark import SparkConf, SparkContext\n",
    "# from pyspark.sql import SparkSession, SQLContext\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *\n",
    "# from Fileops import FileOps as g\n",
    "spark.sql(\"SET TIME ZONE 'EST'\")\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "InputPath='dbfs:/mnt/rs05ue2pipadl03_Readonly/FIONA/RDS/Delhaize/InstacartSourceData/FoodLion/*/*food_lion.pickup_order_metrics.*.csv.gz'\n",
    "delta_table_name = \"merchandising_dev.pos.fdln_pickup_order_metrics\"\n",
    "\n",
    "df_in_delta = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(InputPath)\n",
    "\n",
    "# Read the file with metadata enabled (this is automatic in UC when reading Parquet/CSV)\n",
    "df_in_delta = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(InputPath) \\\n",
    "    .withColumn(\"file_path\", col(\"_metadata.file_path\"))\n",
    "\n",
    "# Extract the file name from the full file path\n",
    "df_in_delta = df_in_delta.withColumn(\n",
    "    \"file_name\",\n",
    "    regexp_extract(col(\"file_path\"), r\".*/([^/]+\\.csv\\.gz)$\", 1)\n",
    ").withColumn(\n",
    "    \"file_date\",\n",
    "    regexp_extract(col(\"file_name\"), r\"(\\d{4}-\\d{2}-\\d{2})\", 1)\n",
    ")\n",
    "\n",
    "df_in_delta.createOrReplaceTempView(\"vw_rpt_8350_foodlion_source\")\n",
    "\n",
    "df_out_pickup_order_metrics=spark.sql(\"\"\" SELECT *,row_number() OVER (PARTITION BY order_id,order_delivery_id ORDER BY file_date desc) as rn from vw_rpt_8350_foodlion_source\"\"\")\n",
    "\n",
    "\n",
    "# Keep only the latest rows per order_id & order_delivery_id\n",
    "df_latest = df_out_pickup_order_metrics.filter(col(\"rn\") == 1).drop(\"rn\").drop(\"file_path\")\n",
    "\n",
    "# Check if Delta table exists at that name\n",
    "if DeltaTable.isDeltaTable(spark, f\"/mnt/delta/{delta_table_name}\"):\n",
    "    delta_table = DeltaTable.forName(spark, delta_table_name)\n",
    "else:\n",
    "    # Create Delta table if it does not exist yet\n",
    "    df_latest.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").saveAsTable(delta_table_name)\n",
    "    delta_table = DeltaTable.forName(spark, delta_table_name)\n",
    "\n",
    "# Merge condition based on order_id and order_delivery_id\n",
    "merge_condition = \"\"\"\n",
    "  target.order_id = source.order_id AND\n",
    "  target.order_delivery_id = source.order_delivery_id\n",
    "\"\"\"\n",
    "\n",
    "# Perform the merge/upsert\n",
    "delta_table.alias(\"target\").merge(\n",
    "    df_latest.alias(\"source\"),\n",
    "    merge_condition\n",
    ").whenMatchedUpdateAll() \\\n",
    " .whenNotMatchedInsertAll() \\\n",
    " .execute()\n",
    "\n",
    "print(\"Merge completed successfully on keys order_id, order_delivery_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47c9b9a8-fd13-4f34-ba3f-ceba69cdea6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5549981530283224,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "fdln_pickup_order_metrics",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
